# ML System Design Doc
## Дизайн ML системы сервиса Margo

Margo - интеллектуальный ассистент-исследователь с интерактивным цифровым аватаром для поиска и объяснения информации в диалоговой форме. Ассистент позволяет:
- искать статьи/видео по интересующей тематике в интернете
- загружать свои статьи/видео во внутреннюю базу данных
- давать краткое саммари по статьям/видео
- отвечать на вопросы по конкретной статье/видео
- сохранять историю вопросов
- выгружать отчеты по истории взаимодействия с пользователем, включая информацию о запросах, ответах и другой связанной активности. Отчеты формируются в удобном формате для анализа и хранения.
- персонализировать цифрового аватара под свои нужды(настраивать внешний вид, стиль речи, манеру объяснения)

### 1. Цели и предпосылки
#### 1.1. Зачем идем в разработку продукта?

- Бизнес-цель:
  - Создать ассистента-исследователя, который будет ускорять изучение новой для пользователя информации и представлять ее в удобной форме через интерактивного аватара.
- Почему станет лучше, чем сейчас, от использования ML
  - Аватар упростит взаимодействие с информацией, снижая когнитивную нагрузку пользователя.
  - Персонализация позволит пользователям получать адаптированные ответы.
  - Использование машинного обучения позволит лучше понимать статьи и выделять ключевые моменты из видео в контексте. Это позволит увеличить скорость получения новой информации для пользователя - ему не придется читать все статьи или смотреть видео целиком.
  -
- Что будем считать успехом итерации с точки зрения бизнеса
  - Реализация MVP с цифровым аватаром, который может суммаризировать статьи и отвечать по ним на вопросы. Цифровой аватар на данном этапе будет единым для всех пользователей без возможности персонализации и представлять собой сгенерированное видео с анимированной иллюстрацией персонажа аниме [Курису Макисэ](https://steins-gate.fandom.com/ru/wiki/%D0%9C%D0%B0%D0%BA%D0%B8%D1%81%D0%B5_%D0%9A%D1%83%D1%80%D0%B8%D1%81%D1%83), который озвучивает ответ на вопрос.

#### 1.2. Бизнес-требования и ограничения

- Краткое описание БТ и ссылки на детальные документы с бизнес-требованиями
  - Интерактивный аватар должен быть простым в использовании, поддерживать мультимодальные запросы (текст, голос) и иметь визуальный интерфейс.
  - Сервис должен поддерживать 8 основные функций:
    - Поиск информации(статьи/видео) в интернете
    - Возможность загрузки материалов пользователя во внутреннюю базу данных
    - Чтение и реферирование текстов
    - Суммаризация материала
    - Извлечение информации из видео (ключевые моменты).
    - Объяснение через видео визуализацию(цифрового аватара)
    - Возможность предоставлять отчеты, в том числе по истории взаимодействия с пользователем
    - Настройка цифрового интерактивного аватара под вкусы пользователя
- Бизнес-ограничения
  - Система должна уметь работать с русским языком
  - Система должна уметь работать в условиях ограниченных ресурсов(в идеале, без видеокарты, на конечном устройстве пользователя или по API)
  - Система должна иметь время отклика меньше 10 секунд
- Что мы ожидаем от конкретной итерации
  - MVP, которое работает на предобученных opensource моделях в открытом доступе(по API)
- Что считаем успешным пилотом? Критерии успеха и возможные пути развития проекта
  - Критерием успеха считаем появление MVP, тестирование на как минимум 30 пользователях и сборе положительной обратной связи(>=50%). Сбор обратной связи будет происходить путем подсчета лайков/дизлайков ответа на вопрос в telegram боте. При сборе обратной связи будет оцениваться только фактический ответ на вопрос, а не качество генерации видео.

#### 1.3. Что входит в скоуп проекта/итерации, что не входит

- На закрытие каких БТ подписываемся в данной итерации
  - В данной итерации подписываемся на:
    - Цифрового аватара в виде сгенерированное видео с анимированной иллюстрацией персонажа аниме
    - LLM агента с инструментами: поиск статей в интернете по свободному текстовому запросу, инструмент для суммаризации, RAG

- Что не будет закрыто: поиск информации по видео, VQA, подбор нейросетевых моделей для задачи и их валидация на тестовых данных, сбор тестовых датасетов для валидации нейросетевых моделей
- Описание результата с точки зрения качества кода и воспроизводимости решения:
  - Репозиторий с модульной структурой (код + тесты).
  - Настроенные CI/CD процессы
  - Описания экспериментов по подбору открытых opensource моделей
- Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации)
  - Доработка аватара в режиме взаимодействия c пользователем realtime
  - Возможность для пользователя задать вопрос голосом
  - Настройка цифрового интерактивного аватара под запросы пользователя(настройка внешности, голоса, манеры объяснять)
  - Возможность загрузки данных пользователя во внутреннюю базу данных

#### 1.4. Предпосылки решения
Для создания системы учитываем следюущие предпосылки:
- Используемые данные: используем только открытые интернет-источники в случае нативного поиска статей по запросу(arxiv, scholar, etc) или пользовательские данные в случае работы с данными пользователя
- Система должна уметь работать как минимум со сторонними открытыми API, дающими доступ к LLM
- Видео цифрового аватара должно быть приятным глазу
- Система должна уметь отвечать только по существу, на основе знаний по тем документам/статьям, которые в нее передали или которые были найдены по текстовому запросу пользователя в интернете

### 2. Методология

#### 2.1. Постановка задачи

Разрабатать систему, состоящую из 4 компонент:
- модуль для генерации видео цифрового аватара
- TG бот
- модуль с LLM агентом для поиска
- модуль с fastapi, который будет оркестрировать модуль с LLM агентом и модуль с генерацией видео цифрового аватара

Модуль с LLM агентом в свою очередь состоит из:
- supervisor для выбора инструментов, которые нужны для ответа на вопрос
- RAG по найденному материалу при ответе на конкретный вопрос
- tool для поиска релевантных статей в интернете
- tool для суммаризации
- кэш для уже найденной информации

#### 2.2. Блок-схема решения

![arch.png](images/arch.png)


#### 2.3. Этапы решения задачи

Всего в данной задаче 2 вещи, которые подразумевают в себе ML - модуль с цифровым аватаром и модуль с LLM агентом. Модуль с LLM агентом в свою очередь содержит три компоненты, которые используют ML - RAG, суммаризация статьи и поиск статей с использованием тулзов(поиска в Arxiv, поиска в PapersWithCode). Все эти компоненты лучше рассмотреть по отдельности:

Компонента поиска модуля LLM  
- Этап 1: Подготовка данных  
Содержит загрузку вопроса пользователя и перефразирование его в форму, пригодную для поиска статей с помощью инструментов. На выходе - перефразированный вопрос пользователя.
- Этап 2: Поиск статей  
Содержит поиск статей по запросу пользователя с помощью инструментов поиска на Arxiv или PapersWithCode. На данном этапе может быть произведен выбор только одного из инструментов в случае, если второй на требудется. Например: пользователь просит найти ему статьи по теме N только на arxiv. На выходе - ссылка на статьи и абстракт из статьи.
- Этап 3: Валидация  
Предполагает оценку качества поиска статей по заданному пользователем вопросу. Считается как количество статей, прочитанных пользователем из результатов поиска по отношению ко всем найденным статьям. Этот этап будет использоваться для дальнейшего улучшения поиска.

Компонента RAG модуля LLM  
- Этап 1: Подготовка данных  
Содержит загрузку статьи, по которой у пользователя есть вопрос, предобработку текста статьи, разбиение ее на чанки согласно выбранному алгоритму, последующая векторизация и сохранение в векторную БД. На выходе - набор эмбеддингов чанков статьи.
*В качестве алгоритма разбиения на чанки может использоваться алгоритм семантического разбиения на чанки, разбиения на чанки с перекрытием по N символов и другие. Необходимо тестирование для выбора наилучшего алгоритма.
- Этап 2: Получение истории запросов пользователя  
Содержит получение истории вопросов пользователя. Будет извлекаться 3 самых последних запроса из истории. На выходе - 3 последних запроса в текстовой форме.
- Этап 3: Подготовка вопроса пользователя  
Содержит получение вопроса, и обогащение его контекстом на основе извлеченной истории запросов. На выход - обогащенный контекстом вопрос пользователя в текстовой форме.
*Пример обогащения контекста:
История запросов пользователя: '[Что такое attention, Покажи формулу attention, Принципы работы self-attention]'
Вопрос пользователя: А что такое матрица Q?
Обогащенный контекстом вопрос пользователя: Объясни, что такое матрица Q в механизме работы self-attention
- Этап 4: Подготовка вопроса пользователя  
Содержит получение вопроса с этапа 3, его предобработку, векторизацию и передачу в систему семантического поиска(на основе векторной БД из этапа 1) для получения чанков, которые отвечают на вопрос пользователя. Выход - эмбеддинг запроса пользователя.
*На данном этапе векторизуется только текст, без обработки картинок и таблиц.
- Этап 5: Семантический поиск  
Является поиском в системе семантического поиска чанков из статьи, которые отвечают на вопрос пользователя по выбранной метрике схожести. На выходе - набор чанков из статьи, которые отвечают на вопрос пользователя, отсортированные в порядке значимости, согласно выбранной метрике расстояния.
*В качестве метрики схожести может использоваться косинусное расстояние, эвклидово расстояние и другие. Необходимо тестирование для выбора наилучшей метрики.
- Этап 6: Получение ответа на вопрос пользователя  
Предполагает передачу семантически близких к вопросу пользователя чанков и вопроса пользователя в LLM модель и получение ответа. На выходе - итоговый ответ на вопрос пользователя.
- Этап 7: Получение обратной связи  
Предполагает оценку метрик [Answer Relevancy](https://docs.confident-ai.com/docs/metrics-answer-relevancy) и [Faithfulness](https://docs.confident-ai.com/docs/metrics-faithfulness) по каждому запросу пользователя и ответу компоненты. Дополнительно будут собираться логи работы компоненты в БД для последующей ручной оценки работы компоненты и формирования валидационной выборки.

Компонента суммаризации модуля LLM  
- Этап 1: Подготовка данных  
Содержит загрузку статьи, по которой пользователь хочет получить саммари, предобработку текста,  разбиение его на чанки согласно выбранному алгоритму. На выходе - набор чанков статьи.
*В качестве алгоритма разбиения на чанки может использоваться алгоритм семантического разбиения на чанки, разбиения на чанки с перекрытием по N символов и другие. Необходимо тестирование для выбора наилучшего алгоритма.
- Этап 2: Суммаризация  
Содержит алгоритм суммаризации map-reduce, в котором сначала происходит суммаризация чанков статьи, а затем последующую суммаризацию саммари чанков в одно саммари. На выходе - саммари по статье.
*Алгоритм суммаризации требует дальнейшего исследования и тестирование на предмет качества суммаризаций больших статей
- Этап 3: Получение обратной связи  
Предполагает оценку метрики [Summarization](https://docs.confident-ai.com/docs/metrics-summarization) по каждому запросу пользователя и ответу компоненты. Дополнительно будут собираться логи работы компоненты в БД для последующей ручной оценки работы компоненты и формирования валидационной выборки.

Модуль с цифровым аватаром  
- Этап 1. Подготовка аудио с ответом  
Содержит получение ответа на вопрос пользователя от модуля LLM агента и перевод его в аудио запись формата .mp3 или .wav на русском языке. На выход - аудиофайл с ответом от модуля с LLM агентом.
- Этап2. Генерация видео ответа  
Содержит генерацию видео по аудио и изображению цифрового аватара с помощью библиотеки SadTalker. На выход - видеофайл с говорящим цифровым аватаром и наложенной аудиодорожкой.
*Этот этап может поменяться на wav2lip + mediapipe
**Вместо ожидаемого изображения цифрового аватара может использоваться изображение живого человека(мало что работает с аниме)
***Валидации на данном этапе не предполагается

### 3. Подготовка пилота

#### 3.1. Способ оценки пилота

- Краткое описание предполагаемого дизайна и способа оценки пилота `Product Owner`, `Data Scientist` with `AB Group`

#### 3.2. Что считаем успешным пилотом

Формализованные в пилоте метрики оценки успешности `Product Owner`

#### 3.3. Подготовка пилота

- Что можем позволить себе, исходя из ожидаемых затрат на вычисления. Если исходно просчитать сложно, то описываем этап расчетов ожидаемой вычислительной сложности на эксперименте с бейзлайном. И предусматриваем уточнение параметров пилота и установку ограничений по вычислительной сложности моделей. `Data Scientist`

### 4. Внедрение `для production систем, если требуется`

> Заполнение раздела 4 требуется не для всех дизайн документов. В некоторых случаях результатом итерации может быть расчет каких-то значений, далее используемых в бизнес-процессе для пилота.

#### 4.1. Архитектура решения

- Блок схема и пояснения: сервисы, назначения, методы API `Data Scientist`

#### 4.2. Описание инфраструктуры и масштабируемости

- Какая инфраструктура выбрана и почему `Data Scientist`
- Плюсы и минусы выбора `Data Scientist`
- Почему финальный выбор лучше других альтернатив `Data Scientist`

#### 4.3. Требования к работе системы

- SLA, пропускная способность и задержка `Data Scientist`

#### 4.4. Безопасность системы

- Потенциальная уязвимость системы `Data Scientist`

#### 4.5. Безопасность данных

- Нет ли нарушений GDPR и других законов `Data Scientist`

#### 4.6. Издержки

- Расчетные издержки на работу системы в месяц `Data Scientist`

#### 4.5. Integration points

- Описание взаимодействия между сервисами (методы API и др.) `Data Scientist`

#### 4.6. Риски

- Описание рисков и неопределенностей, которые стоит предусмотреть `Data Scientist`

> ### Материалы для дополнительного погружения в тему
> - [Шаблон ML System Design Doc [EN] от AWS](https://github.com/eugeneyan/ml-design-docs) и [статья](https://eugeneyan.com/writing/ml-design-docs/) с объяснением каждого раздела
> - [Верхнеуровневый шаблон ML System Design Doc от Google](https://towardsdatascience.com/the-undeniable-importance-of-design-docs-to-data-scientists-421132561f3c) и [описание общих принципов его заполнения](https://towardsdatascience.com/understanding-design-docs-principles-for-achieving-data-scientists-53e6d5ad6f7e).
> - [ML Design Template](https://www.mle-interviews.com/ml-design-template) от ML Engineering Interviews
> - Статья [Design Documents for ML Models](https://medium.com/people-ai-engineering/design-documents-for-ml-models-bbcd30402ff7) на Medium. Верхнеуровневые рекомендации по содержанию дизайн-документа и объяснение, зачем он вообще нужен
> - [Краткий Canvas для ML-проекта от Made with ML](https://madewithml.com/courses/mlops/design/#timeline). Подходит для верхнеуровневого описания идеи, чтобы понять, имеет ли смысл идти дальше.
